import faiss

# è®€å–ç´¢å¼•
index = faiss.read_index("faiss_index/index.faiss")

# æŸ¥çœ‹ç´¢å¼•ç¶­åº¦ã€å‘é‡æ•¸é‡
print("ç¶­åº¦:", index.d)
print("å‘é‡æ•¸é‡:", index.ntotal)

# å› ç‚º FAISS ç´¢å¼•æœ¬èº«åªæœ‰å‘é‡ï¼Œæ–‡ä»¶å…§å®¹æ˜¯å­˜åœ¨æ—é‚Šçš„ index.pkl è£¡ã€‚
# æ‰€ä»¥è¦çœ‹åŸå§‹æ–‡ä»¶ï¼Œè¦ç”¨ LangChain çš„ load_localï¼š

from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from langchain_community.embeddings import OllamaEmbeddings

import os 
from dotenv import load_dotenv
load_dotenv()

# ç’°å¢ƒè®Šæ•¸
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
# embeddings = OpenAIEmbeddings(model="text-embedding-3-small", api_key=OPENAI_API_KEY)

embeddings = OllamaEmbeddings(model="llama3.2:latest")


db = FAISS.load_local("faiss_index", embeddings, allow_dangerous_deserialization=True)

# çœ‹æ‰€æœ‰å­˜çš„æ–‡ä»¶
print(db.docstore._dict)   # ä¸€å€‹ dictï¼Œkey æ˜¯ idï¼Œvalue æ˜¯ Document


# å¦‚æœåªæƒ³æŸ¥ä¸€ç­†ï¼š

for k, v in db.docstore._dict.items():
    print("ğŸ†” ID:", k)
    print("ğŸ“„ å…§å®¹:", v.page_content)
    print("ğŸ“ Metadata:", v.metadata)
    print("-" * 40)